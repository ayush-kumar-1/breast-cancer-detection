{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.models import vision_transformer\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "import os \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(): \n",
    "    training_data = [\"../data/archive/training10_0/training10_0.tfrecords\", \n",
    "        \"../data/archive/training10_1/training10_1.tfrecords\",\n",
    "        \"../data/archive/training10_2/training10_2.tfrecords\",\n",
    "        \"../data/archive/training10_3/training10_3.tfrecords\",\n",
    "        \"../data/archive/training10_4/training10_4.tfrecords\"]\n",
    "\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    feature_dictionary = {\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'label_normal': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image': tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "\n",
    "    def _parse_function(example, feature_dictionary=feature_dictionary):\n",
    "        parsed_example = tf.io.parse_example(example, feature_dictionary)\n",
    "        return parsed_example\n",
    "\n",
    "    def read_data(filename):\n",
    "        full_dataset = tf.data.TFRecordDataset(filename,num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "        full_dataset = full_dataset.shuffle(buffer_size=31000)\n",
    "        full_dataset = full_dataset.cache()\n",
    "        print(\"Size of Training Dataset: \", len(list(full_dataset)))\n",
    "        \n",
    "        feature_dictionary = {\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'label_normal': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image': tf.io.FixedLenFeature([], tf.string)\n",
    "        }   \n",
    "\n",
    "        full_dataset = full_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        print(full_dataset)\n",
    "        for image_features in full_dataset:\n",
    "            image = image_features['image'].numpy()\n",
    "            image = tf.io.decode_raw(image_features['image'], tf.uint8)\n",
    "            image = tf.reshape(image, [299, 299])        \n",
    "            image=image.numpy()\n",
    "            #plt.imshow(image)\n",
    "            images.append(image)\n",
    "            labels.append(image_features['label_normal'].numpy())\n",
    "\n",
    "    for file in training_data:\n",
    "        read_data(file)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "def load_test_data():\n",
    "    # Load .npy file\n",
    "    test_data = np.load('../data/archive/test10_data/test10_data.npy')\n",
    "    test_labels = np.load('../data/archive/test10_labels.npy')\n",
    "\n",
    "    cv_data = np.load('../data/archive/cv10_data/cv10_data.npy')\n",
    "    cv_labels = np.load('../data/archive/cv10_labels.npy')\n",
    "\n",
    "    # combine test and cv into single test set\n",
    "    test_data = np.concatenate((test_data, cv_data), axis=0)\n",
    "    test_labels = np.concatenate((test_labels, cv_labels), axis=0)\n",
    "\n",
    "    return test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 15:02:22.309834: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training Dataset:  11177\n",
      "<ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
      "Size of Training Dataset:  11177\n",
      "<ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
      "Size of Training Dataset:  11177\n",
      "<ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
      "Size of Training Dataset:  11177\n",
      "<ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
      "Size of Training Dataset:  11177\n",
      "<ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = load_train_data()\n",
    "test_images, test_labels = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55885, 299, 299)\n",
      "(55885,)\n",
      "(15364, 299, 299)\n",
      "(15364,)\n"
     ]
    }
   ],
   "source": [
    "# train_images = np.array(train_images)\n",
    "# train_labels = np.array(train_labels)\n",
    "# test_images = np.squeeze(test_images, axis=-1)\n",
    "# test_labels = (test_labels>0).astype(int)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "\n",
    "class NumpyImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform or ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.images[idx], self.labels[idx]\n",
    "        image = np.stack((image,)*3, axis=-1)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    NumpyImageDataset(train_images, train_labels, transform = transform), \n",
    "    batch_size=32, shuffle=False, pin_memory=True)\n",
    "    \n",
    "test_loader=DataLoader(\n",
    "    NumpyImageDataset(test_images, test_labels, transform = transform),\n",
    "    batch_size=32, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "def train(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    y_pred = []\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "            \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        preds = (outputs > 0.5).int()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        y_true += labels.data.cpu().tolist()\n",
    "        y_scores += outputs.squeeze().data.cpu().tolist()\n",
    "        y_pred += preds.cpu().tolist()\n",
    "\n",
    "        if (i % 100 == 0):\n",
    "            auc_roc = roc_auc_score(y_true, y_pred)\n",
    "            precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "            print(f\"Loss: {running_loss/((i+1)*inputs.size(0)):.4f} AUC-ROC: {auc_roc:.4f} Precision: {precision:.4f} Recall: {recall:.4f} F1-score: {f1_score:.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.float() / len(dataloader.dataset)\n",
    "    epoch_auc_roc = roc_auc_score(y_true, y_pred)\n",
    "    epoch_precision, epoch_recall, epoch_f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    print('Train Loss: {:.4f} Acc: {:.4f} AUC-ROC: {:.4f} Precision: {:.4f} Recall: {:.4f} F1-score: {:.4f}'.format(epoch_loss, epoch_acc, epoch_auc_roc, epoch_precision, epoch_recall, epoch_f1_score))\n",
    "    return epoch_loss, epoch_acc, epoch_auc_roc, epoch_precision, epoch_recall, epoch_f1_score\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    y_scores = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.reshape(-1)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = (outputs > 0.5).int()\n",
    "            y_scores.append(preds)\n",
    "    \n",
    "    return y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vision_transformer.vit_b_16(\n",
    "    weights=vision_transformer.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "for param in model.parameters(): \n",
    "    param.requires_grad = False\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "## get and store embeddings\n",
    "model.eval()\n",
    "train_embeddings = []\n",
    "for images, _ in train_loader:\n",
    "    images = images.to(device)\n",
    "    train_embeddings += model(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6016"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_embeddings = torch.stack(train_embeddings)\n",
    "train_dataset = data.TensorDataset(train_embeddings, torch.tensor(train_labels))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(1000, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "shallow_model = MLP().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(shallow_model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55885, 1000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m): \n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshallow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     26\u001b[0m y_pred \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m     auc_roc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     precision, recall, f1_score, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m((i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39minputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m AUC-ROC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc_roc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m F1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:572\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_true)\n\u001b[1;32m    571\u001b[0m     y_true \u001b[39m=\u001b[39m label_binarize(y_true, classes\u001b[39m=\u001b[39mlabels)[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    573\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39;49mmax_fpr),\n\u001b[1;32m    574\u001b[0m         y_true,\n\u001b[1;32m    575\u001b[0m         y_score,\n\u001b[1;32m    576\u001b[0m         average,\n\u001b[1;32m    577\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    581\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39mmax_fpr),\n\u001b[1;32m    582\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    585\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m    586\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:339\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_true)) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not defined in that case.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    344\u001b[0m fpr, tpr, _ \u001b[39m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[39m=\u001b[39msample_weight)\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m max_fpr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m max_fpr \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    train(shallow_model, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6822 AUC-ROC: 0.5000 Precision: 0.0000 Recall: 0.0000 F1-score: 0.0000\n",
      "Loss: 0.4525 AUC-ROC: 0.5000 Precision: 0.0000 Recall: 0.0000 F1-score: 0.0000\n",
      "Loss: 0.4134 AUC-ROC: 0.5000 Precision: 0.0000 Recall: 0.0000 F1-score: 0.0000\n",
      "Loss: 0.3934 AUC-ROC: 0.5000 Precision: 0.0000 Recall: 0.0000 F1-score: 0.0000\n",
      "Loss: 0.3747 AUC-ROC: 0.5003 Precision: 1.0000 Recall: 0.0006 F1-score: 0.0012\n",
      "Loss: 0.3622 AUC-ROC: 0.5007 Precision: 1.0000 Recall: 0.0015 F1-score: 0.0029\n",
      "Loss: 0.3503 AUC-ROC: 0.5022 Precision: 0.9167 Recall: 0.0045 F1-score: 0.0089\n",
      "Loss: 0.3412 AUC-ROC: 0.5053 Precision: 0.9394 Recall: 0.0107 F1-score: 0.0211\n",
      "Loss: 0.3349 AUC-ROC: 0.5132 Precision: 0.9375 Recall: 0.0266 F1-score: 0.0517\n",
      "Loss: 0.3273 AUC-ROC: 0.5184 Precision: 0.9161 Recall: 0.0373 F1-score: 0.0717\n",
      "Loss: 0.3191 AUC-ROC: 0.5236 Precision: 0.9220 Recall: 0.0479 F1-score: 0.0910\n",
      "Loss: 0.3134 AUC-ROC: 0.5277 Precision: 0.9024 Recall: 0.0563 F1-score: 0.1060\n",
      "Loss: 0.3094 AUC-ROC: 0.5320 Precision: 0.8889 Recall: 0.0652 F1-score: 0.1215\n",
      "Loss: 0.3047 AUC-ROC: 0.5375 Precision: 0.8891 Recall: 0.0765 F1-score: 0.1408\n",
      "Loss: 0.3001 AUC-ROC: 0.5419 Precision: 0.8883 Recall: 0.0854 F1-score: 0.1559\n",
      "Loss: 0.2957 AUC-ROC: 0.5454 Precision: 0.8824 Recall: 0.0927 F1-score: 0.1677\n",
      "Loss: 0.2926 AUC-ROC: 0.5511 Precision: 0.8835 Recall: 0.1042 F1-score: 0.1865\n",
      "Loss: 0.2902 AUC-ROC: 0.5545 Precision: 0.8724 Recall: 0.1114 F1-score: 0.1976\n",
      "Train Loss: 0.2884 Acc: 27.4445 AUC-ROC: 0.5557 Precision: 0.8720 Recall: 0.1140 F1-score: 0.2017\n",
      "Loss: 0.2155 AUC-ROC: 0.5000 Precision: 0.0000 Recall: 0.0000 F1-score: 0.0000\n",
      "Loss: 0.2304 AUC-ROC: 0.5874 Precision: 0.8391 Recall: 0.1798 F1-score: 0.2961\n",
      "Loss: 0.2297 AUC-ROC: 0.6074 Precision: 0.8702 Recall: 0.2197 F1-score: 0.3508\n",
      "Loss: 0.2302 AUC-ROC: 0.6225 Precision: 0.8740 Recall: 0.2506 F1-score: 0.3895\n",
      "Loss: 0.2298 AUC-ROC: 0.6251 Precision: 0.8663 Recall: 0.2562 F1-score: 0.3954\n",
      "Loss: 0.2311 AUC-ROC: 0.6260 Precision: 0.8569 Recall: 0.2586 F1-score: 0.3973\n",
      "Loss: 0.2311 AUC-ROC: 0.6286 Precision: 0.8508 Recall: 0.2642 F1-score: 0.4031\n",
      "Loss: 0.2306 AUC-ROC: 0.6308 Precision: 0.8471 Recall: 0.2688 F1-score: 0.4081\n",
      "Loss: 0.2311 AUC-ROC: 0.6305 Precision: 0.8391 Recall: 0.2688 F1-score: 0.4071\n",
      "Loss: 0.2312 AUC-ROC: 0.6328 Precision: 0.8356 Recall: 0.2737 F1-score: 0.4123\n",
      "Loss: 0.2308 AUC-ROC: 0.6349 Precision: 0.8376 Recall: 0.2779 F1-score: 0.4174\n",
      "Loss: 0.2297 AUC-ROC: 0.6361 Precision: 0.8359 Recall: 0.2805 F1-score: 0.4201\n",
      "Loss: 0.2279 AUC-ROC: 0.6378 Precision: 0.8366 Recall: 0.2839 F1-score: 0.4240\n",
      "Loss: 0.2265 AUC-ROC: 0.6403 Precision: 0.8348 Recall: 0.2891 F1-score: 0.4295\n",
      "Loss: 0.2274 AUC-ROC: 0.6413 Precision: 0.8354 Recall: 0.2912 F1-score: 0.4318\n",
      "Loss: 0.2270 AUC-ROC: 0.6435 Precision: 0.8354 Recall: 0.2957 F1-score: 0.4368\n",
      "Loss: 0.2256 AUC-ROC: 0.6446 Precision: 0.8359 Recall: 0.2980 F1-score: 0.4394\n",
      "Loss: 0.2243 AUC-ROC: 0.6461 Precision: 0.8380 Recall: 0.3010 F1-score: 0.4429\n",
      "Train Loss: 0.2242 Acc: 26.7805 AUC-ROC: 0.6466 Precision: 0.8375 Recall: 0.3020 F1-score: 0.4439\n",
      "Loss: 0.2529 AUC-ROC: 0.8141 Precision: 0.8000 Recall: 0.6667 F1-score: 0.7273\n",
      "Loss: 0.2211 AUC-ROC: 0.6699 Precision: 0.8315 Recall: 0.3509 F1-score: 0.4935\n",
      "Loss: 0.2261 AUC-ROC: 0.6639 Precision: 0.8151 Recall: 0.3396 F1-score: 0.4794\n",
      "Loss: 0.2239 AUC-ROC: 0.6612 Precision: 0.8171 Recall: 0.3336 F1-score: 0.4738\n",
      "Loss: 0.2237 AUC-ROC: 0.6646 Precision: 0.8276 Recall: 0.3402 F1-score: 0.4822\n",
      "Loss: 0.2207 AUC-ROC: 0.6646 Precision: 0.8284 Recall: 0.3399 F1-score: 0.4820\n",
      "Loss: 0.2174 AUC-ROC: 0.6637 Precision: 0.8221 Recall: 0.3384 F1-score: 0.4794\n",
      "Loss: 0.2173 AUC-ROC: 0.6643 Precision: 0.8231 Recall: 0.3396 F1-score: 0.4808\n",
      "Loss: 0.2154 AUC-ROC: 0.6654 Precision: 0.8255 Recall: 0.3416 F1-score: 0.4833\n",
      "Loss: 0.2153 AUC-ROC: 0.6665 Precision: 0.8282 Recall: 0.3437 F1-score: 0.4858\n",
      "Loss: 0.2151 AUC-ROC: 0.6680 Precision: 0.8263 Recall: 0.3471 F1-score: 0.4889\n",
      "Loss: 0.2151 AUC-ROC: 0.6696 Precision: 0.8270 Recall: 0.3502 F1-score: 0.4920\n",
      "Loss: 0.2145 AUC-ROC: 0.6705 Precision: 0.8296 Recall: 0.3520 F1-score: 0.4943\n",
      "Loss: 0.2140 AUC-ROC: 0.6703 Precision: 0.8258 Recall: 0.3518 F1-score: 0.4934\n",
      "Loss: 0.2136 AUC-ROC: 0.6711 Precision: 0.8260 Recall: 0.3535 F1-score: 0.4951\n",
      "Loss: 0.2127 AUC-ROC: 0.6721 Precision: 0.8271 Recall: 0.3555 F1-score: 0.4973\n",
      "Loss: 0.2115 AUC-ROC: 0.6731 Precision: 0.8277 Recall: 0.3574 F1-score: 0.4992\n",
      "Loss: 0.2106 AUC-ROC: 0.6749 Precision: 0.8328 Recall: 0.3608 F1-score: 0.5035\n",
      "Train Loss: 0.2101 Acc: 26.5622 AUC-ROC: 0.6754 Precision: 0.8326 Recall: 0.3616 F1-score: 0.5043\n",
      "Loss: 0.1381 AUC-ROC: 0.7500 Precision: 1.0000 Recall: 0.5000 F1-score: 0.6667\n",
      "Loss: 0.1923 AUC-ROC: 0.6800 Precision: 0.8588 Recall: 0.3689 F1-score: 0.5161\n",
      "Loss: 0.2056 AUC-ROC: 0.6827 Precision: 0.8298 Recall: 0.3769 F1-score: 0.5184\n",
      "Loss: 0.2041 AUC-ROC: 0.6891 Precision: 0.8455 Recall: 0.3891 F1-score: 0.5329\n",
      "Loss: 0.2009 AUC-ROC: 0.6886 Precision: 0.8427 Recall: 0.3880 F1-score: 0.5314\n",
      "Loss: 0.2012 AUC-ROC: 0.6885 Precision: 0.8372 Recall: 0.3882 F1-score: 0.5304\n",
      "Loss: 0.2019 AUC-ROC: 0.6895 Precision: 0.8413 Recall: 0.3899 F1-score: 0.5328\n",
      "Loss: 0.2023 AUC-ROC: 0.6899 Precision: 0.8408 Recall: 0.3910 F1-score: 0.5338\n",
      "Loss: 0.2024 AUC-ROC: 0.6904 Precision: 0.8394 Recall: 0.3920 F1-score: 0.5344\n",
      "Loss: 0.2034 AUC-ROC: 0.6921 Precision: 0.8408 Recall: 0.3955 F1-score: 0.5380\n",
      "Loss: 0.2051 AUC-ROC: 0.6922 Precision: 0.8388 Recall: 0.3960 F1-score: 0.5380\n",
      "Loss: 0.2055 AUC-ROC: 0.6912 Precision: 0.8338 Recall: 0.3944 F1-score: 0.5355\n",
      "Loss: 0.2051 AUC-ROC: 0.6905 Precision: 0.8325 Recall: 0.3930 F1-score: 0.5340\n",
      "Loss: 0.2050 AUC-ROC: 0.6918 Precision: 0.8315 Recall: 0.3958 F1-score: 0.5363\n",
      "Loss: 0.2035 AUC-ROC: 0.6926 Precision: 0.8321 Recall: 0.3974 F1-score: 0.5379\n",
      "Loss: 0.2031 AUC-ROC: 0.6918 Precision: 0.8351 Recall: 0.3953 F1-score: 0.5366\n",
      "Loss: 0.2026 AUC-ROC: 0.6928 Precision: 0.8345 Recall: 0.3973 F1-score: 0.5383\n",
      "Loss: 0.2025 AUC-ROC: 0.6920 Precision: 0.8359 Recall: 0.3956 F1-score: 0.5370\n",
      "Train Loss: 0.2022 Acc: 26.4524 AUC-ROC: 0.6926 Precision: 0.8366 Recall: 0.3969 F1-score: 0.5384\n",
      "Loss: 0.1382 AUC-ROC: 0.9808 Precision: 0.8571 Recall: 1.0000 F1-score: 0.9231\n",
      "Loss: 0.1924 AUC-ROC: 0.7167 Precision: 0.8468 Recall: 0.4455 F1-score: 0.5839\n",
      "Loss: 0.1948 AUC-ROC: 0.7084 Precision: 0.8534 Recall: 0.4277 F1-score: 0.5698\n",
      "Loss: 0.1967 AUC-ROC: 0.7089 Precision: 0.8560 Recall: 0.4287 F1-score: 0.5713\n",
      "Loss: 0.1969 AUC-ROC: 0.7055 Precision: 0.8559 Recall: 0.4216 F1-score: 0.5649\n",
      "Loss: 0.1980 AUC-ROC: 0.7051 Precision: 0.8514 Recall: 0.4212 F1-score: 0.5636\n",
      "Loss: 0.1960 AUC-ROC: 0.7037 Precision: 0.8514 Recall: 0.4182 F1-score: 0.5609\n",
      "Loss: 0.1939 AUC-ROC: 0.7061 Precision: 0.8537 Recall: 0.4229 F1-score: 0.5656\n",
      "Loss: 0.1943 AUC-ROC: 0.7070 Precision: 0.8540 Recall: 0.4248 F1-score: 0.5674\n",
      "Loss: 0.1951 AUC-ROC: 0.7063 Precision: 0.8489 Recall: 0.4239 F1-score: 0.5654\n",
      "Loss: 0.1971 AUC-ROC: 0.7053 Precision: 0.8456 Recall: 0.4223 F1-score: 0.5633\n",
      "Loss: 0.1972 AUC-ROC: 0.7031 Precision: 0.8444 Recall: 0.4177 F1-score: 0.5589\n",
      "Loss: 0.1968 AUC-ROC: 0.7024 Precision: 0.8431 Recall: 0.4165 F1-score: 0.5575\n",
      "Loss: 0.1972 AUC-ROC: 0.7032 Precision: 0.8428 Recall: 0.4181 F1-score: 0.5589\n",
      "Loss: 0.1957 AUC-ROC: 0.7034 Precision: 0.8418 Recall: 0.4185 F1-score: 0.5591\n",
      "Loss: 0.1959 AUC-ROC: 0.7023 Precision: 0.8416 Recall: 0.4163 F1-score: 0.5570\n",
      "Loss: 0.1957 AUC-ROC: 0.7016 Precision: 0.8418 Recall: 0.4148 F1-score: 0.5557\n",
      "Loss: 0.1967 AUC-ROC: 0.7015 Precision: 0.8402 Recall: 0.4149 F1-score: 0.5555\n",
      "Train Loss: 0.1963 Acc: 26.3870 AUC-ROC: 0.7023 Precision: 0.8403 Recall: 0.4164 F1-score: 0.5568\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    train(model, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6858283433133733\n",
      "(0.8208955223880597, 0.3842315369261477, 0.5234534330387492, None)\n",
      "0.9087477219474095\n"
     ]
    }
   ],
   "source": [
    "y_hat = evaluate(model, test_loader, criterion)\n",
    "y_pred = []\n",
    "\n",
    "for tens in y_hat: \n",
    "    tens = tens.to('cpu')\n",
    "    y_pred += tens.numpy().flatten().tolist()\n",
    "\n",
    "print(roc_auc_score(test_labels, y_pred))\n",
    "print(precision_recall_fscore_support(test_labels, y_pred, average='binary'))\n",
    "print(accuracy_score(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63bce780ec3e30c588a92f5285e736f5371ca744aafffd65d76efbb3345ddb49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
