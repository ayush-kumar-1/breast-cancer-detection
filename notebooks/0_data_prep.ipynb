{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import torch\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\"../data/archive/training10_0/training10_0.tfrecords\", \n",
    " \"../data/archive/training10_1/training10_1.tfrecords\",\n",
    " \"../data/archive/training10_2/training10_2.tfrecords\",\n",
    " \"../data/archive/training10_3/training10_3.tfrecords\",\n",
    " \"../data/archive/training10_4/training10_4.tfrecords\"]\n",
    "\n",
    "images=[]\n",
    "labels=[]\n",
    "feature_dictionary = {\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "\n",
    "def _parse_function(example, feature_dictionary=feature_dictionary):\n",
    "    parsed_example = tf.io.parse_example(example, feature_dictionary)\n",
    "    return parsed_example\n",
    "\n",
    "def read_data(filename):\n",
    "    full_dataset = tf.data.TFRecordDataset(filename,num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "    full_dataset = full_dataset.shuffle(buffer_size=31000)\n",
    "    full_dataset = full_dataset.cache()\n",
    "    print(\"Size of Training Dataset: \", len(list(full_dataset)))\n",
    "    \n",
    "    feature_dictionary = {\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image': tf.io.FixedLenFeature([], tf.string)\n",
    "    }   \n",
    "\n",
    "    full_dataset = full_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    print(full_dataset)\n",
    "    for image_features in full_dataset:\n",
    "        image = image_features['image'].numpy()\n",
    "        image = tf.io.decode_raw(image_features['image'], tf.uint8)\n",
    "        image = tf.reshape(image, [299, 299])        \n",
    "        image=image.numpy()\n",
    "        #plt.imshow(image)\n",
    "        images.append(image)\n",
    "        labels.append(image_features['label_normal'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .npy file\n",
    "test_data = np.load('../data/archive/test10_data/test10_data.npy')\n",
    "test_labels = np.load('../data/archive/test10_labels.npy')\n",
    "\n",
    "cv_data = np.load('../data/archive/cv10_data/cv10_data.npy')\n",
    "cv_labels = np.load('../data/archive/cv10_labels.npy')\n",
    "\n",
    "# combine test and cv into single test set\n",
    "test_data = np.concatenate((test_data, cv_data), axis=0)\n",
    "test_labels = np.concatenate((test_labels, cv_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training Dataset:  11177\n",
      "<ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
      "Size of Training Dataset:  11177\n",
      "<ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
      "Size of Training Dataset:  11177\n",
      "<ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
      "Size of Training Dataset:  11177\n",
      "<ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
      "Size of Training Dataset:  11177\n",
      "<ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
      "55885\n",
      "55885\n"
     ]
    }
   ],
   "source": [
    "for file in training_data:\n",
    "    read_data(file)\n",
    "    \n",
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NumpyImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform or ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.images[idx], self.labels[idx]\n",
    "        image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Convert numpy arrays to PyTorch Dataset\n",
    "dataset = NumpyImageDataset(images, labels)\n",
    "\n",
    "# Create DataLoader with batch size of 32\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63bce780ec3e30c588a92f5285e736f5371ca744aafffd65d76efbb3345ddb49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
